{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_images', 'breed_labels.csv', '.DS_Store', 'test', 'train_metadata', 'color_labels.csv', 'test_sentiment', 'test_metadata', 'train_sentiment', 'train', 'train_images', 'state_labels.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sm \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cassic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "_uuid": "3868330a6629974af996d414e08673b0bf3d097a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 24)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/train/train.csv')\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993,)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_y = train['AdoptionSpeed']\n",
    "train.drop(columns = 'AdoptionSpeed', inplace=True)\n",
    "\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 23)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 23)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../input/test/test.csv')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18941, 23)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Breed1 = df.Breed1.astype('category')\n",
    "df.Breed2 = df.Breed1.astype('category')  \n",
    "df.Vaccinated = df.Vaccinated.astype('category')   \n",
    "df.Dewormed = df.Dewormed.astype('category')   \n",
    "df.Sterilized = df.Sterilized.astype('category')   \n",
    "df.State = df.State.astype('category')   \n",
    "df.Description = df.Description.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DescLen'] = df.Description.astype(str).fillna('').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_log = ['Age', 'Quantity', 'Fee', 'PhotoAmt', 'VideoAmt', 'DescLen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[cols_log] = df[cols_log].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "#Now lets assign a labels to our quality variable\n",
    "label_cat = LabelEncoder()\n",
    "df['RescuerID'] = label_cat.fit_transform(df['RescuerID'])\n",
    "df['Breed1'] = label_cat.fit_transform(df['Breed1'])\n",
    "df['Breed2'] = label_cat.fit_transform(df['Breed2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RescuerID'] = df['RescuerID'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['NameLen'] = np.log1p(df['Name'].astype(str).fillna('').apply(len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13268\n",
       "7    4113 \n",
       "5    559  \n",
       "6    501  \n",
       "4    263  \n",
       "3    237  \n",
       "Name: Color3, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Color3.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):    \n",
    "    for row in df.index:\n",
    "        if df.loc[row,'Color1'] == i or df.loc[row,'Color2'] == i or df.loc[row,'Color3'] == i:\n",
    "            df.loc[row,'color_'+str(i)] = 1\n",
    "        else:\n",
    "            df.loc[row,'color_'+str(i)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_cols=['Gender', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
    "       'Sterilized','Health']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=one_hot_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "sel_cols = ['Type', 'Age', 'Breed1', 'Breed2', 'Quantity', 'Fee', 'State', #'RescuerID',\n",
    "       'VideoAmt', 'PhotoAmt',  'DescLen', 'NameLen', 'color_0', 'color_1', 'color_2', 'color_3', 'color_4',\n",
    "       'color_5', 'color_6', 'color_7', 'Gender_2', 'Gender_3',\n",
    "       'MaturitySize_2', 'MaturitySize_3', 'MaturitySize_4', 'FurLength_2',\n",
    "       'FurLength_3', 'Vaccinated_2', 'Vaccinated_3', 'Dewormed_2',\n",
    "       'Dewormed_3', 'Sterilized_2', 'Sterilized_3', 'Health_2', 'Health_3']\n",
    "\n",
    "df_ml = df[sel_cols]\n",
    "df_ml.State = df_ml.State.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml.State = df_ml.State.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ml = df_ml.iloc[0:14993,]\n",
    "test_ml = df_ml.iloc[14993:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14993, 34)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ml.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3948, 34)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ml.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First model classic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_ml,\n",
    "                                                    train_y, #Y\n",
    "                                                    random_state=123, #seed\n",
    "                                                    stratify=train_y, #have a representative sample\n",
    "                                                    test_size=0.3) #using 30% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10495,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ml.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3732770120053357\n",
      "mean : 0.382512077432113, sd: 0.009687013917437327\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# model = AdaBoostClassifier(n_estimators=9)\n",
    "# model.fit(X_train, y_train)\n",
    "# print(model.score(X_test, y_test))\n",
    "# scores = cross_val_score(model,train_ml,train_y, cv=5)\n",
    "# model.fit(train_ml, train_y)\n",
    "\n",
    "# print('mean : {0}, sd: {1}'.format(scores.mean(), scores.std()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type              int64  \n",
       "Age               float64\n",
       "Breed1            int64  \n",
       "Breed2            int64  \n",
       "Quantity          float64\n",
       "Fee               float64\n",
       "State             int64  \n",
       "VideoAmt          float64\n",
       "PhotoAmt          float64\n",
       "DescLen           float64\n",
       "NameLen           float64\n",
       "color_0           float64\n",
       "color_1           float64\n",
       "color_2           float64\n",
       "color_3           float64\n",
       "color_4           float64\n",
       "color_5           float64\n",
       "color_6           float64\n",
       "color_7           float64\n",
       "Gender_2          uint8  \n",
       "Gender_3          uint8  \n",
       "MaturitySize_2    uint8  \n",
       "MaturitySize_3    uint8  \n",
       "MaturitySize_4    uint8  \n",
       "FurLength_2       uint8  \n",
       "FurLength_3       uint8  \n",
       "Vaccinated_2      uint8  \n",
       "Vaccinated_3      uint8  \n",
       "Dewormed_2        uint8  \n",
       "Dewormed_3        uint8  \n",
       "Sterilized_2      uint8  \n",
       "Sterilized_3      uint8  \n",
       "Health_2          uint8  \n",
       "Health_3          uint8  \n",
       "dtype: object"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ml.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.015, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=1, missing=None, n_estimators=500,\n",
       "       n_jobs=1, nthread=-1, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = xgb.XGBClassifier(n_estimators=500, nthread=-1, max_depth=8, learning_rate=0.015)\n",
    "# model.fit(train_ml.values, train_y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('learner', RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split..._jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=False,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline#, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# default params\n",
    "m = RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "             max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
    "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "             min_samples_leaf=1, min_samples_split=2,\n",
    "             min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=1,\n",
    "             oob_score=False, random_state=1, verbose=False,\n",
    "             warm_start=False)\n",
    "pre = StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "p = Pipeline([('preprocessing',pre ),('learner', m) ])\n",
    "p.fit(train_ml.values, train_y.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:617: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/base.py:465: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, y, **fit_params).transform(X)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/pipeline.py:511: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  Xt = transform.transform(Xt)\n"
     ]
    }
   ],
   "source": [
    "#scores = cross_val_score(p,train_ml,train_y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4169258447684954\n",
      "0.01002491018596111\n"
     ]
    }
   ],
   "source": [
    "#print(scores.mean())\n",
    "#print(scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_ml.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6479258939828583"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quadratic_weighted_kappa(train_y.values, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(test_ml.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv('../input/test/sample_submission.csv')\n",
    "sample.AdoptionSpeed = pred\n",
    "sample.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The following 3 functions have been taken from Ben Hamner's github repository\n",
    "# # https://github.com/benhamner/Metrics\n",
    "# def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "#     \"\"\"\n",
    "#     Returns the confusion matrix between rater's ratings\n",
    "#     \"\"\"\n",
    "#     assert(len(rater_a) == len(rater_b))\n",
    "#     if min_rating is None:\n",
    "#         min_rating = min(rater_a + rater_b)\n",
    "#     if max_rating is None:\n",
    "#         max_rating = max(rater_a + rater_b)\n",
    "#     num_ratings = int(max_rating - min_rating + 1)\n",
    "#     conf_mat = [[0 for i in range(num_ratings)]\n",
    "#                 for j in range(num_ratings)]\n",
    "#     for a, b in zip(rater_a, rater_b):\n",
    "#         conf_mat[a - min_rating][b - min_rating] += 1\n",
    "#     return conf_mat\n",
    "\n",
    "\n",
    "# def histogram(ratings, min_rating=None, max_rating=None):\n",
    "#     \"\"\"\n",
    "#     Returns the counts of each type of rating that a rater made\n",
    "#     \"\"\"\n",
    "#     if min_rating is None:\n",
    "#         min_rating = min(ratings)\n",
    "#     if max_rating is None:\n",
    "#         max_rating = max(ratings)\n",
    "#     num_ratings = int(max_rating - min_rating + 1)\n",
    "#     hist_ratings = [0 for x in range(num_ratings)]\n",
    "#     for r in ratings:\n",
    "#         hist_ratings[r - min_rating] += 1\n",
    "#     return hist_ratings\n",
    "\n",
    "\n",
    "# def quadratic_weighted_kappa(y, y_pred):\n",
    "#     \"\"\"\n",
    "#     Calculates the quadratic weighted kappa\n",
    "#     axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "#     value, which is a measure of inter-rater agreement between two raters\n",
    "#     that provide discrete numeric ratings.  Potential values range from -1\n",
    "#     (representing complete disagreement) to 1 (representing complete\n",
    "#     agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "#     chance.\n",
    "#     quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "#     each correspond to a list of integer ratings.  These lists must have the\n",
    "#     same length.\n",
    "#     The ratings should be integers, and it is assumed that they contain\n",
    "#     the complete range of possible ratings.\n",
    "#     quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "#     is the minimum possible rating, and max_rating is the maximum possible\n",
    "#     rating\n",
    "#     \"\"\"\n",
    "#     rater_a = y\n",
    "#     rater_b = y_pred\n",
    "#     min_rating=None\n",
    "#     max_rating=None\n",
    "#     rater_a = np.array(rater_a, dtype=int)\n",
    "#     rater_b = np.array(rater_b, dtype=int)\n",
    "#     assert(len(rater_a) == len(rater_b))\n",
    "#     if min_rating is None:\n",
    "#         min_rating = min(min(rater_a), min(rater_b))\n",
    "#     if max_rating is None:\n",
    "#         max_rating = max(max(rater_a), max(rater_b))\n",
    "#     conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "#                                 min_rating, max_rating)\n",
    "#     num_ratings = len(conf_mat)\n",
    "#     num_scored_items = float(len(rater_a))\n",
    "\n",
    "#     hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "#     hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "#     numerator = 0.0\n",
    "#     denominator = 0.0\n",
    "\n",
    "#     for i in range(num_ratings):\n",
    "#         for j in range(num_ratings):\n",
    "#             expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "#                               / num_scored_items)\n",
    "#             d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "#             numerator += d * conf_mat[i][j] / num_scored_items\n",
    "#             denominator += d * expected_count / num_scored_items\n",
    "\n",
    "#     return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
